{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import swifter\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import json\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "#         print(col)\n",
    "        col_type = df[col].dtype\n",
    "                \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage(deep=True).sum() / 1024 ** 2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(train_data, val_data, merge_data_path_list, done_files=[], merge_cols='', flag=0):\n",
    "    compulsory_cols = [\"query_id\", \"user_id\", \"session_id\", \"product_id\"]\n",
    "    for path in merge_data_path_list:\n",
    "        print(\"Merging file...\", path.split('/')[-1])\n",
    "        prev_cols_train = set(train_data.columns.tolist())\n",
    "        prev_cols_val = set(val_data.columns.tolist())\n",
    "        d = pd.read_csv(path)\n",
    "#         d = reduce_mem_usage(d)\n",
    "        if 'is_click' in d.columns.tolist():\n",
    "            d = d.drop('is_click', 1)\n",
    "        if flag==0:\n",
    "            merge_cols = [d.columns[0]]\n",
    "            \n",
    "        for col in d.columns.tolist():\n",
    "            if col in train_data.columns.tolist() and col not in compulsory_cols and col not in merge_cols:\n",
    "                d = d.drop(col, 1)\n",
    "            \n",
    "        train_data = train_data.merge(d, on=merge_cols, how='left')\n",
    "        val_data = val_data.merge(d, on=merge_cols, how='left')\n",
    "#         print(\"Train: \", train_data.shape, \"Val: \", val_data.shape)\n",
    "        done_files.append(path)\n",
    "#         print(\"Added columns train: \", set(train_data.columns.tolist()) - prev_cols_train)\n",
    "#         print(\"Added columns val: \", set(val_data.columns.tolist()) - prev_cols_val)\n",
    "        del d\n",
    "        gc.collect()\n",
    "    print(\"Train: \", train_data.shape, \"Val: \", val_data.shape)\n",
    "    \n",
    "    return train_data, val_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
